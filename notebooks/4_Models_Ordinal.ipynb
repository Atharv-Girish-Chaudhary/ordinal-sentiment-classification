{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”§ Notebook 4: Ordinal Models\n",
    "## Final Project - Ordinal vs Nominal Sentiment Analysis\n",
    "### Atharv Chaudhary\n",
    "\n",
    "---\n",
    "\n",
    "**Purpose:** Train and evaluate ORDINAL classification models.\n",
    "\n",
    "**Models:**\n",
    "1. Ridge Regression (treats ratings as continuous)\n",
    "2. Ordinal Logistic Regression (threshold-based)\n",
    "\n",
    "**Input:** `amazon_electronics_cleaned.csv`\n",
    "\n",
    "**Output:** `ordinal_results.csv`, confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    mean_absolute_error, \n",
    "    f1_score, \n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Settings\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"âœ… Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data & Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "df = pd.read_csv('amazon_electronics_cleaned.csv')\n",
    "print(f\"âœ… Loaded {len(df):,} reviews\")\n",
    "\n",
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "y = df['rating'].values\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"âœ… Training: {X_train.shape[0]:,} | Test: {X_test.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"Evaluate model and return metrics.\"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"\\n{'='*55}\")\n",
    "    print(f\"ðŸ“Š {model_name}\")\n",
    "    print(f\"{'='*55}\")\n",
    "    print(f\"Accuracy:      {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"MAE:           {mae:.4f}\")\n",
    "    print(f\"F1 (macro):    {f1_macro:.4f}\")\n",
    "    print(f\"F1 (weighted): {f1_weighted:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'encoding': 'Ordinal',\n",
    "        'accuracy': accuracy,\n",
    "        'mae': mae,\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_weighted': f1_weighted\n",
    "    }\n",
    "\n",
    "\n",
    "def calculate_error_rates(y_true, y_pred):\n",
    "    \"\"\"Calculate adjacent and severe error rates.\"\"\"\n",
    "    errors = y_true != y_pred\n",
    "    if errors.sum() == 0:\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    error_distances = np.abs(y_true[errors] - y_pred[errors])\n",
    "    adjacent = (error_distances == 1).sum() / errors.sum()\n",
    "    severe = (error_distances >= 2).sum() / errors.sum()\n",
    "    \n",
    "    return adjacent, severe\n",
    "\n",
    "\n",
    "print(\"âœ… Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model 1 - Ridge Regression (Ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODEL 1: RIDGE REGRESSION (ORDINAL)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ”§ MODEL 1: Ridge Regression (Ordinal)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nTreats ratings as CONTINUOUS ordinal values: 1 < 2 < 3 < 4 < 5\")\n",
    "print(\"Formula: Å· = wáµ€x + b, then round to nearest integer\")\n",
    "print(\"Loss: Î£(yáµ¢ - Å·áµ¢)Â² + Î»||w||Â² (naturally penalizes large errors more)\")\n",
    "\n",
    "# Train\n",
    "ridge_model = Ridge(alpha=1.0, random_state=RANDOM_STATE)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict (continuous) then round and clip\n",
    "ridge_pred_continuous = ridge_model.predict(X_test)\n",
    "ridge_pred = np.clip(np.round(ridge_pred_continuous), 1, 5).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "ridge_results = evaluate_model(y_test, ridge_pred, \"Ridge Regression\")\n",
    "\n",
    "# Error analysis\n",
    "ridge_adjacent, ridge_severe = calculate_error_rates(y_test, ridge_pred)\n",
    "ridge_results['adjacent_error'] = ridge_adjacent\n",
    "ridge_results['severe_error'] = ridge_severe\n",
    "\n",
    "print(f\"\\nError Analysis:\")\n",
    "print(f\"   Adjacent Error Rate (Â±1): {ridge_adjacent:.2%}\")\n",
    "print(f\"   Severe Error Rate (Â±2+):  {ridge_severe:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show continuous prediction distribution\n",
    "print(\"\\nðŸ“Š Ridge Continuous Predictions:\")\n",
    "print(f\"   Min: {ridge_pred_continuous.min():.2f}\")\n",
    "print(f\"   Max: {ridge_pred_continuous.max():.2f}\")\n",
    "print(f\"   Mean: {ridge_pred_continuous.mean():.2f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nðŸ“‹ Classification Report - Ridge:\")\n",
    "print(classification_report(y_test, ridge_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model 2 - Ordinal Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ORDINAL LOGISTIC REGRESSION CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class OrdinalLogisticRegression:\n",
    "    \"\"\"\n",
    "    Ordinal Logistic Regression using threshold (cumulative) approach.\n",
    "    \n",
    "    For K classes, trains K-1 binary classifiers.\n",
    "    Each classifier k models: P(Y â‰¤ k | x) = Ïƒ(Î¸â‚– - wáµ€x)\n",
    "    \n",
    "    This EXPLICITLY preserves ordinal structure: 1 < 2 < 3 < 4 < 5\n",
    "    \n",
    "    Key insight: Same feature weights w for all thresholds,\n",
    "    only the threshold Î¸â‚– changes.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_iter=1000, C=1.0):\n",
    "        self.max_iter = max_iter\n",
    "        self.C = C\n",
    "        self.classifiers = []\n",
    "        self.classes_ = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.sort(np.unique(y))\n",
    "        n_classes = len(self.classes_)\n",
    "        \n",
    "        print(f\"   Training {n_classes - 1} binary classifiers...\")\n",
    "        print(f\"   Classes: {self.classes_}\")\n",
    "        \n",
    "        # Train K-1 binary classifiers for cumulative probabilities\n",
    "        for k in range(n_classes - 1):\n",
    "            threshold = self.classes_[k]\n",
    "            # Binary target: 1 if y <= threshold, 0 otherwise\n",
    "            y_binary = (y <= threshold).astype(int)\n",
    "            \n",
    "            clf = LogisticRegression(\n",
    "                max_iter=self.max_iter, \n",
    "                C=self.C,\n",
    "                random_state=42,\n",
    "                solver='lbfgs'\n",
    "            )\n",
    "            clf.fit(X, y_binary)\n",
    "            self.classifiers.append(clf)\n",
    "            \n",
    "            pos_rate = y_binary.mean()\n",
    "            print(f\"      Classifier {k+1}: P(Y â‰¤ {threshold}) - {pos_rate:.1%} positive\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities using cumulative approach.\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        n_classes = len(self.classes_)\n",
    "        \n",
    "        # Get cumulative probabilities P(Y â‰¤ k)\n",
    "        cumulative_probs = np.zeros((n_samples, n_classes))\n",
    "        cumulative_probs[:, -1] = 1.0  # P(Y â‰¤ max_class) = 1\n",
    "        \n",
    "        for k, clf in enumerate(self.classifiers):\n",
    "            cumulative_probs[:, k] = clf.predict_proba(X)[:, 1]\n",
    "        \n",
    "        # Convert cumulative to class probabilities: P(Y = k) = P(Y â‰¤ k) - P(Y â‰¤ k-1)\n",
    "        class_probs = np.zeros((n_samples, n_classes))\n",
    "        class_probs[:, 0] = cumulative_probs[:, 0]  # P(Y = 1) = P(Y â‰¤ 1)\n",
    "        \n",
    "        for k in range(1, n_classes):\n",
    "            class_probs[:, k] = cumulative_probs[:, k] - cumulative_probs[:, k-1]\n",
    "        \n",
    "        # Ensure non-negative (numerical stability)\n",
    "        class_probs = np.maximum(class_probs, 0)\n",
    "        \n",
    "        # Normalize rows to sum to 1\n",
    "        row_sums = class_probs.sum(axis=1, keepdims=True)\n",
    "        row_sums[row_sums == 0] = 1  # Avoid division by zero\n",
    "        class_probs = class_probs / row_sums\n",
    "        \n",
    "        return class_probs\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels.\"\"\"\n",
    "        probs = self.predict_proba(X)\n",
    "        return self.classes_[np.argmax(probs, axis=1)]\n",
    "\n",
    "\n",
    "print(\"âœ… OrdinalLogisticRegression class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODEL 2: ORDINAL LOGISTIC REGRESSION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ”§ MODEL 2: Ordinal Logistic Regression (Threshold-Based)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nUses K-1 binary classifiers to model cumulative probabilities.\")\n",
    "print(\"Formula: P(Y â‰¤ k | x) = Ïƒ(Î¸â‚– - wáµ€x)\")\n",
    "print(\"Class prob: P(Y = k) = P(Y â‰¤ k) - P(Y â‰¤ k-1)\")\n",
    "print(\"\\nExplicitly encodes ordinal constraint: Î¸â‚ < Î¸â‚‚ < Î¸â‚ƒ < Î¸â‚„\\n\")\n",
    "\n",
    "# Train\n",
    "olr_model = OrdinalLogisticRegression(max_iter=1000, C=1.0)\n",
    "olr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "print(\"\\n   Making predictions...\")\n",
    "olr_pred = olr_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "olr_results = evaluate_model(y_test, olr_pred, \"Ordinal Logistic Regression\")\n",
    "\n",
    "# Error analysis\n",
    "olr_adjacent, olr_severe = calculate_error_rates(y_test, olr_pred)\n",
    "olr_results['adjacent_error'] = olr_adjacent\n",
    "olr_results['severe_error'] = olr_severe\n",
    "\n",
    "print(f\"\\nError Analysis:\")\n",
    "print(f\"   Adjacent Error Rate (Â±1): {olr_adjacent:.2%}\")\n",
    "print(f\"   Severe Error Rate (Â±2+):  {olr_severe:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"\\nðŸ“‹ Classification Report - Ordinal LR:\")\n",
    "print(classification_report(y_test, olr_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFUSION MATRICES\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Ridge Regression\n",
    "cm_ridge = confusion_matrix(y_test, ridge_pred)\n",
    "sns.heatmap(cm_ridge, annot=True, fmt='d', cmap='Oranges', ax=axes[0],\n",
    "            xticklabels=[1, 2, 3, 4, 5], yticklabels=[1, 2, 3, 4, 5])\n",
    "axes[0].set_xlabel('Predicted Rating', fontsize=11)\n",
    "axes[0].set_ylabel('Actual Rating', fontsize=11)\n",
    "axes[0].set_title(f'Ridge Regression (Ordinal)\\nAccuracy: {ridge_results[\"accuracy\"]:.2%}', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "\n",
    "# Ordinal Logistic Regression\n",
    "cm_olr = confusion_matrix(y_test, olr_pred)\n",
    "sns.heatmap(cm_olr, annot=True, fmt='d', cmap='Purples', ax=axes[1],\n",
    "            xticklabels=[1, 2, 3, 4, 5], yticklabels=[1, 2, 3, 4, 5])\n",
    "axes[1].set_xlabel('Predicted Rating', fontsize=11)\n",
    "axes[1].set_ylabel('Actual Rating', fontsize=11)\n",
    "axes[1].set_title(f'Ordinal Logistic Regression\\nAccuracy: {olr_results[\"accuracy\"]:.2%}', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrices_ordinal.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Saved: confusion_matrices_ordinal.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SAVE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "# Combine results\n",
    "ordinal_results = pd.DataFrame([ridge_results, olr_results])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“Š ORDINAL MODELS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(ordinal_results.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "ordinal_results.to_csv('ordinal_results.csv', index=False)\n",
    "print(\"\\nâœ… Saved: ordinal_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'actual': y_test,\n",
    "    'ridge_pred': ridge_pred,\n",
    "    'olr_pred': olr_pred\n",
    "})\n",
    "predictions_df.to_csv('ordinal_predictions.csv', index=False)\n",
    "print(\"âœ… Saved: ordinal_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('ordinal_results.csv')\n",
    "    files.download('confusion_matrices_ordinal.png')\n",
    "except:\n",
    "    print(\"Files saved locally\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## âœ… Summary\n",
    "\n",
    "**Ordinal Models Trained:**\n",
    "\n",
    "| Model | Accuracy | MAE | Adjacent Error | Severe Error |\n",
    "|-------|----------|-----|----------------|---------------|\n",
    "| Ridge Regression | See above | See above | See above | See above |\n",
    "| Ordinal LR | See above | See above | See above | See above |\n",
    "\n",
    "**Key Insight:** Ordinal models should have LOWER severe error rates because they understand that 1â†’5 is worse than 4â†’5.\n",
    "\n",
    "**Next:** Run `5_Results_Analysis.ipynb` to compare all models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
