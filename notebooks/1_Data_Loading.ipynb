{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° Tip: Install tqdm for progress bars: pip install tqdm\n",
      "‚úÖ Libraries imported\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import json\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try to import tqdm for progress bars (optional)\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    HAS_TQDM = True\n",
    "except ImportError:\n",
    "    HAS_TQDM = False\n",
    "    print(\"üí° Tip: Install tqdm for progress bars: pip install tqdm\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Sample size: 50,000\n",
      "  Random state: 42\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "SAMPLE_SIZE = 50000  # Number of reviews to load (increase for final run)\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Sample size: {SAMPLE_SIZE:,}\")\n",
    "print(f\"  Random state: {RANDOM_STATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING AMAZON ELECTRONICS REVIEWS DATASET\n",
      "Source: UCSD McAuley Lab (Stanford SNAP)\n",
      "======================================================================\n",
      "\n",
      "Downloading 50,000 reviews...\n",
      "‚è≥ This may take 1-2 minutes...\n",
      "\n",
      "‚ö†Ô∏è  tqdm not available, using basic progress...\n",
      "  Loaded 10,000 reviews...\n",
      "  Loaded 20,000 reviews...\n",
      "  Loaded 30,000 reviews...\n",
      "  Loaded 40,000 reviews...\n",
      "\n",
      "‚úÖ SUCCESS! Loaded 50,000 reviews\n",
      "   Columns: ['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText', 'overall', 'summary', 'unixReviewTime', 'reviewTime']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LOAD AMAZON ELECTRONICS REVIEWS (2014 Dataset - Reliable)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LOADING AMAZON ELECTRONICS REVIEWS DATASET\")\n",
    "print(\"Source: UCSD McAuley Lab (Stanford SNAP)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "url = \"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz\"\n",
    "\n",
    "print(f\"\\nDownloading {SAMPLE_SIZE:,} reviews...\")\n",
    "print(\"‚è≥ This may take 1-2 minutes...\\n\")\n",
    "\n",
    "try:\n",
    "    import time\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    # Download file with progress\n",
    "    start_time = time.time()\n",
    "    print(\"üì• Downloading dataset...\")\n",
    "    urllib.request.urlretrieve(url, 'data/electronics.json.gz')\n",
    "    download_time = time.time() - start_time\n",
    "    print(f\"‚úÖ Download complete ({download_time:.1f}s)\")\n",
    "    \n",
    "    # Load JSONL.gz file with progress bar\n",
    "    print(\"\\nüìñ Loading reviews...\")\n",
    "    reviews = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with gzip.open('data/electronics.json.gz', 'rt', encoding='utf-8') as f:\n",
    "        # Use tqdm for progress bar if available, otherwise fallback\n",
    "        try:\n",
    "            for i, line in enumerate(tqdm(f, total=SAMPLE_SIZE, desc=\"Loading\", unit=\"reviews\")):\n",
    "                if i >= SAMPLE_SIZE:\n",
    "                    break\n",
    "                try:\n",
    "                    review = json.loads(line)\n",
    "                    # Validate required fields\n",
    "                    if 'overall' in review and 'reviewText' in review:\n",
    "                        reviews.append(review)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue  # Skip malformed lines\n",
    "        except:\n",
    "            # Fallback without tqdm\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= SAMPLE_SIZE:\n",
    "                    break\n",
    "                if i % 10000 == 0 and i > 0:\n",
    "                    print(f\"  Loaded {i:,} reviews...\")\n",
    "                try:\n",
    "                    review = json.loads(line)\n",
    "                    if 'overall' in review and 'reviewText' in review:\n",
    "                        reviews.append(review)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "    \n",
    "    load_time = time.time() - start_time\n",
    "    df_raw = pd.DataFrame(reviews)\n",
    "    \n",
    "    print(f\"\\n‚úÖ SUCCESS! Loaded {len(df_raw):,} reviews in {load_time:.1f}s\")\n",
    "    print(f\"   Columns: {df_raw.columns.tolist()}\")\n",
    "    print(f\"   Memory usage: {df_raw.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "    \n",
    "except ImportError:\n",
    "    # Fallback if tqdm not available\n",
    "    print(\"‚ö†Ô∏è  tqdm not available, using basic progress...\")\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, 'data/electronics.json.gz')\n",
    "        reviews = []\n",
    "        with gzip.open('data/electronics.json.gz', 'rt', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= SAMPLE_SIZE:\n",
    "                    break\n",
    "                if i % 10000 == 0 and i > 0:\n",
    "                    print(f\"  Loaded {i:,} reviews...\")\n",
    "                try:\n",
    "                    review = json.loads(line)\n",
    "                    if 'overall' in review and 'reviewText' in review:\n",
    "                        reviews.append(review)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "        df_raw = pd.DataFrame(reviews)\n",
    "        print(f\"\\n‚úÖ SUCCESS! Loaded {len(df_raw):,} reviews\")\n",
    "        print(f\"   Columns: {df_raw.columns.tolist()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        df_raw = None\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    df_raw = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Raw Data Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AO94DHGC771SJ</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>amazdnu</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Gotta have GPS!</td>\n",
       "      <td>1370131200</td>\n",
       "      <td>06 2, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMO214LNFCEI4</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>[12, 15]</td>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Very Disappointed</td>\n",
       "      <td>1290643200</td>\n",
       "      <td>11 25, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3N7T0DY83Y4IG</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>C. A. Freeman</td>\n",
       "      <td>[43, 45]</td>\n",
       "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1st impression</td>\n",
       "      <td>1283990400</td>\n",
       "      <td>09 9, 2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin     reviewerName   helpful  \\\n",
       "0   AO94DHGC771SJ  0528881469          amazdnu    [0, 0]   \n",
       "1   AMO214LNFCEI4  0528881469  Amazon Customer  [12, 15]   \n",
       "2  A3N7T0DY83Y4IG  0528881469    C. A. Freeman  [43, 45]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  We got this GPS for my husband who is an (OTR)...      5.0   \n",
       "1  I'm a professional OTR truck driver, and I bou...      1.0   \n",
       "2  Well, what can I say.  I've had this unit in m...      3.0   \n",
       "\n",
       "             summary  unixReviewTime   reviewTime  \n",
       "0    Gotta have GPS!      1370131200   06 2, 2013  \n",
       "1  Very Disappointed      1290643200  11 25, 2010  \n",
       "2     1st impression      1283990400   09 9, 2010  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview raw data\n",
    "print(\"\\nüìã Raw Data Preview:\")\n",
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATA CLEANING\n",
      "======================================================================\n",
      "\n",
      "Original size: 50,000 reviews\n",
      "\n",
      "üìä Missing values:\n",
      "   text: 0 (0.00%)\n",
      "   rating: 0 (0.00%)\n",
      "‚úÖ After removing nulls: 50,000 reviews (100.0% retained)\n",
      "\n",
      "üìè Short reviews (<10 chars): 40\n",
      "‚úÖ After removing short reviews: 49,960 reviews\n",
      "‚úÖ After rating validation: 49,960 reviews\n",
      "\n",
      "üîÑ Found 7 duplicate reviews\n",
      "‚úÖ After removing duplicates: 49,953 reviews\n",
      "\n",
      "======================================================================\n",
      "‚úÖ Final cleaned dataset: 49,953 reviews\n",
      "   Data retention: 99.9%\n",
      "   Memory usage: 30.6 MB\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DATA CLEANING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATA CLEANING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Validate input\n",
    "if df_raw is None or len(df_raw) == 0:\n",
    "    raise ValueError(\"‚ùå No data loaded! Check previous cell for errors.\")\n",
    "\n",
    "# Rename columns to standard names\n",
    "df = df_raw.rename(columns={\n",
    "    'overall': 'rating',\n",
    "    'reviewText': 'text'\n",
    "}).copy()\n",
    "\n",
    "print(f\"\\nOriginal size: {len(df):,} reviews\")\n",
    "\n",
    "# Keep only relevant columns (with error handling)\n",
    "required_cols = ['text', 'rating']\n",
    "missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"‚ùå Missing required columns: {missing_cols}\")\n",
    "\n",
    "df = df[required_cols].copy()\n",
    "\n",
    "# Step 1: Remove missing values\n",
    "missing_before = df.isna().sum()\n",
    "print(f\"\\nüìä Missing values:\")\n",
    "print(f\"   text: {missing_before['text']:,} ({missing_before['text']/len(df)*100:.2f}%)\")\n",
    "print(f\"   rating: {missing_before['rating']:,} ({missing_before['rating']/len(df)*100:.2f}%)\")\n",
    "\n",
    "df = df.dropna(subset=['text', 'rating'])\n",
    "print(f\"‚úÖ After removing nulls: {len(df):,} reviews ({len(df)/len(df_raw)*100:.1f}% retained)\")\n",
    "\n",
    "# Step 2: Remove very short reviews\n",
    "short_reviews = (df['text'].str.len() < 10).sum()\n",
    "print(f\"\\nüìè Short reviews (<10 chars): {short_reviews:,}\")\n",
    "df = df[df['text'].str.len() >= 10]\n",
    "print(f\"‚úÖ After removing short reviews: {len(df):,} reviews\")\n",
    "\n",
    "# Step 3: Convert rating to integer (with validation)\n",
    "try:\n",
    "    df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
    "    invalid_ratings = df['rating'].isna().sum()\n",
    "    if invalid_ratings > 0:\n",
    "        print(f\"‚ö†Ô∏è  Found {invalid_ratings:,} invalid ratings (non-numeric)\")\n",
    "        df = df.dropna(subset=['rating'])\n",
    "    df['rating'] = df['rating'].astype(int)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error converting ratings: {e}\")\n",
    "    raise\n",
    "\n",
    "# Step 4: Verify ratings are 1-5\n",
    "invalid_range = (~df['rating'].between(1, 5)).sum()\n",
    "if invalid_range > 0:\n",
    "    print(f\"‚ö†Ô∏è  Found {invalid_range:,} ratings outside 1-5 range\")\n",
    "df = df[df['rating'].between(1, 5)]\n",
    "print(f\"‚úÖ After rating validation: {len(df):,} reviews\")\n",
    "\n",
    "# Step 5: Remove duplicate reviews (optional but recommended)\n",
    "duplicates = df.duplicated(subset=['text']).sum()\n",
    "if duplicates > 0:\n",
    "    print(f\"\\nüîÑ Found {duplicates:,} duplicate reviews\")\n",
    "    df = df.drop_duplicates(subset=['text'], keep='first')\n",
    "    print(f\"‚úÖ After removing duplicates: {len(df):,} reviews\")\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Final validation\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"‚úÖ Final cleaned dataset: {len(df):,} reviews\")\n",
    "print(f\"   Data retention: {len(df)/len(df_raw)*100:.1f}%\")\n",
    "print(f\"   Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Cleaned Data Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not going to write a long review, even thought...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've had mine for a year and here's what we go...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  rating\n",
       "0  We got this GPS for my husband who is an (OTR)...       5\n",
       "1  I'm a professional OTR truck driver, and I bou...       1\n",
       "2  Well, what can I say.  I've had this unit in m...       3\n",
       "3  Not going to write a long review, even thought...       2\n",
       "4  I've had mine for a year and here's what we go...       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview cleaned data\n",
    "print(\"\\nüìã Cleaned Data Preview:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CLASS DISTRIBUTION\n",
      "======================================================================\n",
      "\n",
      "üìä Rating Distribution:\n",
      "   1 ‚≠ê:  2,835 (  5.7%) ‚ñà‚ñà\n",
      "   2 ‚≠ê:  2,160 (  4.3%) ‚ñà‚ñà\n",
      "   3 ‚≠ê:  3,963 (  7.9%) ‚ñà‚ñà‚ñà\n",
      "   4 ‚≠ê: 10,101 ( 20.2%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   5 ‚≠ê: 30,894 ( 61.8%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "   Total: 49,953 reviews\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CLASS DISTRIBUTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CLASS DISTRIBUTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "rating_counts = df['rating'].value_counts().sort_index()\n",
    "\n",
    "print(\"\\nüìä Rating Distribution:\")\n",
    "for rating, count in rating_counts.items():\n",
    "    pct = count / len(df) * 100\n",
    "    bar = '‚ñà' * int(pct / 2)\n",
    "    print(f\"   {rating} ‚≠ê: {count:>6,} ({pct:>5.1f}%) {bar}\")\n",
    "\n",
    "print(f\"\\n   Total: {len(df):,} reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Class Imbalance Analysis:\n",
      "   Majority class (5-star): 30,894\n",
      "   Minority class: 2,160\n",
      "   Imbalance ratio: 14.3:1\n"
     ]
    }
   ],
   "source": [
    "# Check class imbalance\n",
    "print(\"\\n‚ö†Ô∏è Class Imbalance Analysis:\")\n",
    "majority_class = rating_counts.max()\n",
    "minority_class = rating_counts.min()\n",
    "imbalance_ratio = majority_class / minority_class\n",
    "\n",
    "print(f\"   Majority class (5-star): {majority_class:,}\")\n",
    "print(f\"   Minority class: {minority_class:,}\")\n",
    "print(f\"   Imbalance ratio: {imbalance_ratio:.1f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Text Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEXT STATISTICS\n",
      "======================================================================\n",
      "\n",
      "üìè Review Length (characters):\n",
      "   Min:    10\n",
      "   Max:    15,567\n",
      "   Mean:   578\n",
      "   Median: 337\n",
      "\n",
      "üìù Word Count:\n",
      "   Min:    2\n",
      "   Max:    2,845\n",
      "   Mean:   105\n",
      "   Median: 63\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TEXT STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TEXT STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Calculate text length\n",
    "df['text_length'] = df['text'].str.len()\n",
    "df['word_count'] = df['text'].str.split().str.len()\n",
    "\n",
    "print(\"\\nüìè Review Length (characters):\")\n",
    "print(f\"   Min:    {df['text_length'].min():,}\")\n",
    "print(f\"   Max:    {df['text_length'].max():,}\")\n",
    "print(f\"   Mean:   {df['text_length'].mean():,.0f}\")\n",
    "print(f\"   Median: {df['text_length'].median():,.0f}\")\n",
    "\n",
    "print(\"\\nüìù Word Count:\")\n",
    "print(f\"   Min:    {df['word_count'].min():,}\")\n",
    "print(f\"   Max:    {df['word_count'].max():,}\")\n",
    "print(f\"   Mean:   {df['word_count'].mean():,.0f}\")\n",
    "print(f\"   Median: {df['word_count'].median():,.0f}\")\n",
    "\n",
    "# Drop helper columns before saving\n",
    "df = df.drop(columns=['text_length', 'word_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SAVING DATA\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Saved to: amazon_electronics_cleaned.csv\n",
      "   Rows: 49,953\n",
      "   Columns: ['text', 'rating']\n",
      "\n",
      "‚úÖ Verified: Loaded 49,953 rows from saved file\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SAVE CLEANED DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SAVING DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save to CSV\n",
    "output_file = 'data/amazon_electronics_cleaned.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Saved to: {output_file}\")\n",
    "print(f\"   Rows: {len(df):,}\")\n",
    "print(f\"   Columns: {list(df.columns)}\")\n",
    "\n",
    "# Verify save\n",
    "df_verify = pd.read_csv(output_file)\n",
    "print(f\"\\n‚úÖ Verified: Loaded {len(df_verify):,} rows from saved file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab - file saved locally\n"
     ]
    }
   ],
   "source": [
    "# Download for Google Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(output_file)\n",
    "    print(\"üì• Download started...\")\n",
    "except:\n",
    "    print(\"Not in Colab - file saved locally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìã NOTEBOOK 1 COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Dataset: Amazon Electronics Reviews\n",
      "Source: UCSD McAuley Lab\n",
      "Reviews: 49,953\n",
      "Output: amazon_electronics_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìã NOTEBOOK 1 COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nDataset: Amazon Electronics Reviews\")\n",
    "print(f\"Source: UCSD McAuley Lab\")\n",
    "print(f\"Reviews: {len(df):,}\")\n",
    "print(f\"Output: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
